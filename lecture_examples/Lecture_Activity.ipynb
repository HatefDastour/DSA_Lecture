{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture Activity\n",
    "\n",
    "In this activity, you will work in small groups to analyze one of the following datasets. Your tasks are as follows:\n",
    "\n",
    "1. Choose the most suitable method for handling missing data from the techniques discussed today (either dropping or imputing).\n",
    "1. Discuss the potential considerations for the approach you selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Weather Data Example\n",
    "\n",
    "This dataset contains daily temperature records for Columbia, Missouri, spanning from January 15, 2024, to November 15, 2024. The temperatures are provided in both standard and metric units. The data was collected by the [University of Missouri Weather Station](https://www.ncei.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USC00231801/detail) and sourced from the National Centers for Environmental Information (NCEI), a division of NOAA. You can access the original data source here: [NCEI Climate Data](https://www.ncei.noaa.gov/cdo-web/).\n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/HatefDastour/DSA_Lecture/refs/heads/main/images/weather_station_figure.jpg\" alt=\"University of Missouri Weather Station\" width=\"500\">\n",
    "</center>\n",
    "\n",
    "**Dataset Details:** Each file includes daily minimum and maximum temperature readings, with some files containing intentional missing values (NaNs) for exercises in data cleaning and imputation.\n",
    "\n",
    "- **Metric Units** ([data_2024_metric_missing.csv](https://raw.githubusercontent.com/HatefDastour/DSA_Lecture/refs/heads/main/data_files/data_2024_metric_missing.csv)):\n",
    "  - **PRCP**: Daily Precipitation (inches)\n",
    "  - **TMIN**: Minimum Daily Temperature (째C)  \n",
    "  - **TMAX**: Maximum Daily Temperature (째C)  \n",
    "\n",
    "- **Standard Units** ([data_2024_standard_missing.csv](https://raw.githubusercontent.com/HatefDastour/DSA_Lecture/refs/heads/main/data_files/data_2024_standard_missing.csv)):  \n",
    "  - **PRCP**: Daily Precipitation (mm)\n",
    "  - **TMIN**: Minimum Daily Temperature (째F)  \n",
    "  - **TMAX**: Maximum Daily Temperature (째F)  \n",
    "\n",
    "**Note:** This dataset is intended for **educational use only**. Although based on historical data, it has been modified for training purposes to illustrate techniques for handling missing data in Python and may not be suitable for operational weather analysis or forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Set unit system: 'standard' (Fahrenheit, inches) or 'metric' (Celsius, mm)\n",
    "unit_system = 'standard'\n",
    "# unit_system = 'metric'  # Uncomment to switch to metric\n",
    "\n",
    "# URL of the CSV file with climate data (includes missing values)\n",
    "link = f'https://raw.githubusercontent.com/HatefDastour/DSA_Lecture/refs/heads/main/data_files/data_2024_{unit_system}_missing.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame, using the first column as the index\n",
    "climate_data = pd.read_csv(link, index_col=0)\n",
    "\n",
    "# Convert the index to datetime format for time series analysis\n",
    "climate_data.index = pd.to_datetime(climate_data.index)\n",
    "\n",
    "# Display the DataFrame to check data loading\n",
    "display(climate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Your Analyses ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Missouri Monthly Unemployment Claims by Industry Overview\n",
    "\n",
    "This dataset represents monthly unemployment claims in Missouri across five industries from August 2011 to October 2024. It includes both complete and missing-value variants, making it useful for exploring temporal patterns in unemployment and developing imputation techniques for missing data.\n",
    "\n",
    "This dataset is sourced from the [State of Missouri Data Portal](https://data.mo.gov/). You can access the original data source here: [Missouri Monthly Unemployment Claims by Industry](https://data.mo.gov/Labor/Missouri-Monthly-Unemployment-Claims-By-Industry/cj66-t7xq/about_data).\n",
    "\n",
    "**Dataset Details:** This dataset includes monthly unemployment claims with some entries containing intentional missing values (NaNs) for exercises in data cleaning and imputation.\n",
    "\n",
    "- **Unemployment Claims Dataset** ([monthly_unemployment_missing.csv](https://raw.githubusercontent.com/HatefDastour/DSA_Lecture/refs/heads/main/data_files/monthly_unemployment_missing.csv)):\n",
    "\n",
    "**Industries Included:**  \n",
    "- Administrative & Support/Waste Management/Remediation Services\n",
    "- Manufacturing\n",
    "- Construction\n",
    "- Health Care & Social Assistance\n",
    "- Accommodation & Food Services\n",
    "\n",
    "**Note:** This dataset is intended for **educational use only**. Although based on historical data, it has been modified for training purposes to illustrate techniques for handling missing data in Python and may not be suitable for operational analysis or forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the CSV file with unemployment claims data (includes missing values)\n",
    "link = 'https://raw.githubusercontent.com/HatefDastour/DSA_Lecture/refs/heads/main/data_files/monthly_unemployment_missing.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame, using the first column as the index\n",
    "unemployment_data = pd.read_csv(link, index_col=0)\n",
    "\n",
    "# Convert the index to datetime format for time series analysis\n",
    "unemployment_data.index = pd.to_datetime(unemployment_data.index)\n",
    "\n",
    "# Display the DataFrame to check data loading\n",
    "display(unemployment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Your Analyses ---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
